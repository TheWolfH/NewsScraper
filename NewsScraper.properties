! This file is used to configure the behavior of the NewsScraper application prototype
!
! While all properties can be changed, DO NOT delete any of the key/value pairs or this file, it will
! cause undefined application behavior. Constraints and other comments are denoted before the 
! respective property.

# Specifies which of the data sources specified in the helpers.DataSource enum should be examined when
# running the application. Must be a comma-separated list (no whitespace) of values that match the name
# of the respective Enum entry exactly, or the special value "ALL" to use all defined data sources.
#
# Currently supported data sources are:
# GUARDIAN,SPIEGELONLINE,SPIEGEL,TELEGRAPH,ZEIT,TAGESSPIEGEL,STERN,MIRROR,DAILYMAIL
General.DataSource.usedDataSources = ALL

# Specifies the User Agent header to send when performing search requests.
Scraper.searchArticles.userAgent = Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0

# Specifies the User Agent header to send when fetching the article content to populate the ScrapedArticle
# object.
ScrapedArticle.populateData.userAgent = Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0

# The minimum level any log entry must possess to be written to log.txt. Must be a valid String according
# to java.util.logging.Level.parse(), e.g. either one of the known log levels or an integer.
# Warning: Any level above CONFIG (700) will possibly lead to thousands of log lines, may slow down the
# application and should only be used for debugging!
General.logging.level = INFO

# Number of threads to use when populating the article objects (via Fetcher.populateArticleData() and
# Article.populateData()). Numbers > 32 tend to lead to the spiegel.de server blocking the application
# from accessing articles
Fetcher.populateArticleData.numThreads = 32